

# TCP和UDP的比较

![image-20210301113445929](http://haoimg.hifool.cn/img/image-20210301113445929.png)

TCP怎么做到可靠传输？

* 滑动窗口算法
* 流量控制算法

# epoll原理详解

[epoll原理](https://blog.csdn.net/daaikuaichuan/article/details/83862311)

select & poll 的缺点：

1. **单个进程能够监视的文件描述符的数量存在最大限制，通常是1024**，当然可以更改数量，但由于select采用轮询的方式扫描文件描述符，文件描述符数量越多，性能越差；(在linux内核头文件中，有这样的定义：#define __FD_SETSIZE  1024)
    1. poll使用链表保存文件描述符，因此没有了监视文件数量的限制，但其他三个缺点依然存在。
2. **内核 / 用户空间内存拷贝问题，select需要复制大量的句柄数据结构，产生巨大的开销**；
3. **select返回的是含有整个句柄的数组，应用程序需要遍历整个数组才能发现哪些句柄发生了事件；**
4. **select的触发方式是水平触发**，应用程序如果没有完成对一个已经就绪的文件描述符进行IO操作，那么之后每次select调用还是会将这些文件描述符通知进程。

拿select模型为例，假设我们的服务器需要支持100万的并发连接，

* select则在__FD_SETSIZE 为1024的情况下，则我们至少需要开辟1k个进程才能实现100万的并发连接。
* 除了进程间上下文切换的时间消耗外，从内核/用户空间大量的无脑内存拷贝、数组轮询等，是系统难以承受的。
* 因此，基于select模型的服务器程序，要达到10万级别的并发访问，是一个很难完成的任务。





epoll通过在Linux内核中申请一个简易的文件系统(文件系统一般用什么数据结构实现？B+树)。

* **通过红黑树和双链表数据结构，并结合回调机制，造就了epoll的高效。**

把原先的select/poll调用分成了3个部分：

* 调用epoll_create()建立一个epoll对象(在epoll文件系统中为这个句柄对象分配资源)
    * 此调用返回一个句柄，之后所有的使用都依靠这个句柄来标识。
* 调用epoll_ctl向epoll对象中添加这100万个连接的套接字
    * 通过此调用向epoll对象中添加、删除、修改感兴趣的事件，返回0标识成功，返回-1表示失败。
* 调用epoll_wait收集发生的事件的连接
    * 通过此调用收集收集在epoll监控中已经发生的事件。
    * 调用epoll_wait时，并没有一股脑的向操作系统复制这100万个连接的句柄数据，内核也不需要去遍历全部的连接。



# http请求过程

- 域名解析
- 发起TCP3次握手
- 建立TCP连接后发起http请求
- 服务器响应请求，返回结果
- 浏览器得到html标签代码
- 浏览器解析html代码中的资源，例如js，css，img等
- 浏览器对页面进行渲染并呈现给用户