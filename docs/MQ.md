# 消息队列的作用：

异步：

* 同步操作需要等待。一些非必要的业务逻辑可以用异步操作，节约时间。
* 和线程池有什么区别：线程池需要进行对线程进行管理，需要有较大的代码变动
* 随着项目的**请求链路越来越长**，会越来越慢。

削峰：

* 让系统按照处理速度慢慢从消息队列拉取消息处理，这种短暂的消息积压是有必要的。

解耦：

* 子系统之间解耦，接入新的子系统无需修改原来的代码。
* 传统的软件开发模式，模块之间的调用是直接调用，这样的系统很不利于系统的扩展，同时，模块之间的相互调用，数据之间的共享问题也很大，每个模块都要时时刻刻考虑其他模块会不会挂了；
* 使用消息队列以后，模块之间不直接调用，而是通过数据，且当某个模块挂了以后，数据仍旧会保存在消息队列中。

---



# 分布式事务

一个服务在与其他服务相关联时，怎么保证多个事务都成功

## ACID

- **原子性（atomicity）**：一个事务是一个不可分割的工作单位，事务中包括的操作要么都做，要么都不做。
- **一致性（consistency）**：事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。
- **隔离性（isolation）**：一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
- **持久性（durability）**：**持久性也称永久性（permanence）**，指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。

## 分布式事务



# 消息队列组件

- rocketmq-client：提供发送、接受消息的客户端API。
- rocketmq-namesrv：类似于Zookeeper，**这里保存着消息的TopicName，队列等运行时的元信息**。
- rocketmq-broker：**接受生产者发来的消息并存储**（通过调用rocketmq-store），**消费者从这里取得消息**
- rocketmq-common：**通用的一些类，方法，数据结构**等。
- rocketmq-remoting：基于Netty4的client/server + fastjson**序列化 + 自定义二进制协议**。
- rocketmq-store：**消息、索引存储**等。
- rocketmq-filtersrv：**消息过滤器Server**，需要注意的是，要实现这种过滤，需要上传代码到MQ！（一般而言，我们利用Tag足以满足大部分的过滤需求，如果更灵活更复杂的过滤需求，可以考虑filtersrv组件）。
- rocketmq-tools：命令行工具。

## name-server

**NameServer**压力不会太大，平时主要开销是在维持心跳和**提供Topic-Broker的关系数据**。

* Broker向NameServer发心跳时， 会带上当前自己所负责的所有**Topic**信息，
* 如果**Topic**个数太多（万级别），会导致一次心跳中，就Topic的数据就几十M，网络情况差的话， 网络传输失败，心跳失败，导致NameServer误认为Broker心跳失败。

**NameServer** 被设计成几乎无状态的，可以横向扩展，节点之间相互之间无通信，通过部署多台机器来标记自己是一个伪集群。

* 每个 Broker 在启动的时候会到 NameServer 注册，
* Producer 在发送消息前会根据 Topic 到 **NameServer** 获取到 Broker 的路由信息，
* Consumer 也会定时获取 Topic 的路由信息。



## producer

消息生产者，负责产生消息，一般由业务系统负责产生消息。

**Producer**由用户进行分布式部署，消息由**Producer**通过多种负载均衡模式发送到**Broker**集群，发送低延时，支持快速失败。



**RocketMQ** 提供了三种方式发送消息：同步、异步和单向

- **同步发送**：同步发送指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包。
    - 一般用于重要通知消息，例如重要通知邮件、营销短信。
- **异步发送**：异步发送指发送方发出数据后，不等接收方发回响应，接着发送下个数据包，
    - 一般用于可能链路耗时较长而对响应时间敏感的业务场景，例如用户视频上传后通知启动转码服务。
- **单向发送**：单向发送是指只负责发送消息而不等待服务器回应且没有回调函数触发，
    - 适用于某些耗时非常短但对可靠性要求并不高的场景，例如日志收集。



## broker

消息中转角色，负责**存储消息**，转发消息。

- **Broker**是具体提供业务的服务器，单个Broker节点与所有的NameServer节点保持长连接及心跳，并会定时将**Topic**信息注册到NameServer，
    - 顺带一提底层的通信和连接都是**基于Netty实现**的。
- **Broker**负责消息存储，
    - 以Topic为纬度支持轻量级的队列，单机可以支撑上万队列规模，支持消息推拉模型。
- 官网上有数据显示：具有**上亿级消息堆积能力**，同时可**严格保证消息的有序性**



## consumer

消息消费者，负责消费消息，一般是后台系统负责异步消费。

- **Consumer**也由用户部署，支持PUSH和PULL两种消费模式，支持**集群消费**和**广播消息**，提供**实时的消息订阅机制**。
- **Pull**：拉取型消费者（Pull Consumer）主动从消息服务器拉取信息，只要批量拉取到消息，用户应用就会启动消费过程，所以 Pull 称为主动消费型。
- **Push**：推送型消费者（Push Consumer）封装了消息的拉取、消费进度和其他的内部维护工作，将消息到达时执行的回调接口留给用户应用程序来实现。
    - 所以 Push 称为被动消费类型，但从实现上看还是从消息服务器中拉取消息，
    - 不同于 Pull 的是 Push 首先要注册消费监听器，当监听器处触发后才开始消费消息。



# 消息领域模型

![image-20210302132644963](http://haoimg.hifool.cn/img/image-20210302132644963.png)

## Message

**Message**（消息）就是要传输的信息。

一条消息必须有一个主题（Topic），主题可以看做是你的信件要邮寄的地址。

一条消息也可以拥有一个可选的标签（Tag）和额处的键值对，它们可以用于设置一个业务 Key 并在 Broker 上查找此消息以便在开发期间查找问题。

## Topic

**Topic**（主题）可以看做消息的规类，它是消息的第一级类型。比如一个电商系统可以分为：交易消息、物流消息等，一条消息必须有一个 Topic 。

**Topic** 与生产者和消费者的关系非常松散，一个 Topic 可以有0个、1个、多个生产者向其发送消息，一个生产者也可以同时向不同的 Topic 发送消息。

一个 Topic 也可以被 0个、1个、多个消费者订阅。

## Tag

**Tag**（标签）可以看作子主题，它是消息的第二级类型，用于为用户提供额外的灵活性。

使用标签，同一业务模块不同目的的消息就可以用相同 Topic 而不同的 **Tag** 来标识。

比如交易消息又可以分为：交易创建消息、交易完成消息等，一条消息可以没有 **Tag** 。

标签有助于保持您的代码干净和连贯，并且还可以为 **RocketMQ** 提供的查询系统提供帮助。

## Group

分组，一个组可以订阅多个Topic。

分为ProducerGroup，ConsumerGroup，代表某一类的生产者和消费者，一般来说同一个服务可以作为Group，同一个Group一般来说发送和消费的消息都是一样的

## Queue

在**Kafka**中叫Partition，每个Queue内部是有序的，

在**RocketMQ**中分为读和写两种队列，一般来说读写队列数量一致，如果不一致就会出现很多问题。

## Message Queue

**Message Queue**（消息队列），主题被划分为一个或多个子主题，即消息队列。

一个 Topic 下可以设置多个消息队列，发送消息时执行该消息的 Topic ，RocketMQ 会轮询该 Topic 下的所有队列将消息发出去。

消息的物理管理单位。一个Topic下可以有多个Queue，Queue的引入使得消息的存储可以分布式集群化，具有了水平扩展能力。

## Offset

在**RocketMQ** 中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是指队列中的每个存储单元都是定长，访问其中的存储单元使用Offset 来访问，Offset 为 java long 类型，64 位，理论上在 100年内不会溢出，所以认为是长度无限。

也可以认为 Message Queue 是一个长度无限的数组，**Offset** 就是下标。

## 消息消费模式

消息消费模式有两种：**Clustering**（集群消费）和**Broadcasting**（广播消费）。

默认情况下就是集群消费，该模式下一个消费者集群共同消费一个主题的多个队列，一个队列只会被一个消费者消费，如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。

而广播消费消息会发给消费者组中的每一个消费者进行消费。

## Message Order

**Message Order**（消息顺序）有两种：**Orderly**（顺序消费）和**Concurrently**（并行消费）。

顺序消费表示消息消费的顺序同生产者为每个消息队列发送的顺序一致，所以如果正在处理全局顺序是强制性的场景，需要确保使用的主题只有一个消息队列。

并行消费不再保证消息顺序，消费的最大并行数量受每个消费者客户端指定的线程池限制。



---

# 面试可能会问道的问题

## 1 为什么使用消息队列？

异步：同步操作需要等待。一些非必要的业务逻辑可以用异步操作，节约时间。

削峰：大量请求直接打到redis或者DB上，压力过大。让系统按照处理速度慢慢从消息队列拉取消息处理，这种短暂的消息积压是有必要的。

解耦：子系统之间解耦，接入新的子系统无需修改原来的代码。传统的软件开发模式，模块之间的调用是直接调用，这样的系统很不利于系统的扩展，同时，模块之间的相互调用，数据之间的共享问题也很大，每个模块都要时时刻刻考虑其他模块会不会挂了；使用消息队列以后，模块之间不直接调用，而是通过数据，且当某个模块挂了以后，数据仍旧会保存在消息队列中。最典型的就是生产者-消费者模式，本案例使用的就是该模式；

**秒杀系统主要是为了削峰**

## 2 缺点？

- 系统**可用性降低**：**消息队列挂了，系统也会挂掉。**
- 如何保证消息**不被重复消费**？
- 如何保证消息**不丢失**？
- 如何保证消息**按顺序消费**？



## 3 消息队列如何选型？

1. Kafka技术通常是在大数据的实时数据计算领域，**模型简单，qps高，但是会有消息重复消费**问题。

2. RabbitMq 用erlang写的，有四种发布订阅模型，缺点是**吞吐量不高，且不是分布式mq**。

3. RocketMq 是阿里开源的组件，用java写的，吞吐量高，社区活跃度低于RabbitMq。



---



## 4 如何保证消息队列是高可用的？

**引入mq会导致可用性降低，mq一旦挂掉，系统也会挂掉。**

rabbitmq：

* rabbitmq是一个**非分布式MQ**，基于主从模式做高可用。
* **普通集群模式**：queue存放在一个节点，其他节点只有queue的元数据（配置信息），如果访问了其他节点，就会去queue所在节点拉数据。
* **镜像集群模式**：queue的元数据和消息都存在与所有节点，每次写数据都进行同步。消费消息时，ack消息通过循环链表发送，每个queue都要消除缓存消息。  坏处：开销大

kafka的高可用：（感觉好像是Raft啊）

* 生产者往leader里写数据
* leader把数据同步到follwer。
* 消费者消费leader的数据。
* leader挂掉则选举出新的leader



## 5 如何保证消息不被重复消费/幂等性？

幂等

* 数学上的概念
* 同样的参数多次调用同一个接口和调用一次产生的结果是一致的。



保证消息幂等性，需要结合具体的业务来讨论。

* **Mysql**：
    * 如果是对mysql **insert**操作
        * 做一个**唯一的主键**，出现重复消费就会导致主键冲突，然后事务回滚。避免数据库出现**脏数据**。
    * 如果是对mysql **update**操作
        * 那么加个**version**字段做版本控制。

* 如果是**redis**，
    * 那么set操作天然就是幂等性的。
* 如果是**更复杂的业务场景**
    * 根据APPname，接口名，主机名创建一个全局幂等id存入redis，或者内存set，或者数据库的幂等表中，
    * 每次先进行幂等性判断。
* 在实习的津贴项目中
    * 针对幂等性的解决方案是设计一个**幂等表**，
    * 核心业务逻辑都需要**先通过幂等ID查幂等表，保证幂等性**。



---

## 6 如何解决一条消息能被多次消费？

`RabbitMQ` 就是采用队列模型

* 通过 `Exchange` 模块来将消息发送至多个队列，解决一条消息需要被多个消费者消费问题。
* 通过多队列全量存储相同的消息，即数据的冗余可以实现一条消息被多个消费者消费。



发布/订阅模型

* 该模型是将消息发往一个Topic即主题中，
* 所有订阅了这个 Topic 的订阅者都能消费这条消息。



发布订阅模型

* 为让一条消息可以被多个消费者消费

队列模型

* 队列模型每条消息只能被一个消费者消费
* 队列模型也可以通过消息全量存储至多个队列来解决一条消息被多个消费者消费问题，但是会有数据的冗余。

---

## 7 如何保证消费的可靠性传输？

要保证可靠传输，需要从生产者，消费者，消息队列三个方面考虑。

* **生产者写消息过程需要有确认机制**。
    * 设置生产者confirm模式，如果rabbitmq收到消息，则调用ack回调函数确认，否则调用nack回调函数表示未收到，进行重传。
* **消费者拿到消息，没来得及处理就挂掉了**。
    * 创建消费者时，autoack参数设为false，等到处理完业务逻辑后手动ack确认，出现异常就不会消费掉消息。
* rabbitmq数据默认在内存中，需要将exchanger，queue和**消息持久化**。
    * exchanger和queue通过设置durable参数为true可以持久化。
    * 消息创建时添加一个delivery_mode = true参数
* **利用rabbitmq的镜像集群模式**。
    * 在此模式下，queue的元数据和消息都存在与所有节点，每次写数据都进行同步。

kafka丢数据  选举leader时，follower刚好有数据没有同步，怎么做？

* 每个leader至少两个follower，每条消息必须复制到副本才认为写成功了。
* **生厂者设置一旦写入失败，就无限重试。**



## 8 如何保证消息的顺序性？

全局有序：

* 如果要保证消息的全局有序，首先只能由一个生产者往Topic发送消息，并且一个Topic内部只能有一个队列（分区）。
* 消费者也必须是单线程消费这个队列。这样的消息就是全局有序的！
* 一般情况下我们都不需要全局有序



部分有序：

* 因此绝大部分的有序需求是**部分有序**，
* 部分有序我们就可以将Topic内部划分成我们需要的队列数，把消息通过特定的策略发往固定的队列中，保证顺序性的消息写入同一个queue
* 然后每个队列对应一个单线程处理的消费者。
* 这样即完成了部分有序的需求，又可以通过队列数量的并发来提高消息处理效率。



![image-20210305191536295](http://haoimg.hifool.cn/img/image-20210305191536295.png)

---



## 9 消息积压怎么办？

消息的堆积往往是因为**生产者的生产速度与消费者的消费速度不匹配**。

* 有可能是因为消息消费失败反复重试造成的，
* 也有可能就是消费者消费能力弱，渐渐地消息就积压了。



因此我们需要**先定位消费慢的原因**，

* 如果是`bug`则处理 `bug` ，如果是因为本身消费能力较弱，
* 我们可以优化下消费逻辑，比如之前是一条一条消息消费处理的，这次我们批量处理，比如数据库的插入，一条一条插和批量插效率是不一样的。



假如逻辑我们已经都优化了，但还是慢，

* 那就得考虑水平扩容了，增加`Topic`的队列数和消费者数量，
* **注意队列数一定要增加**，不然新增加的消费者是没东西消费的。
* **一个Topic中，一个队列只会分配给一个消费者**。



当然你消费者内部是单线程还是多线程消费那看具体场景。

* 不过要注意上面提高的消息丢失的问题，如果你是将接受到的消息写入**内存队列**之后，然后就返回响应给`Broker`，然后多线程向内存队列消费消息，假设此时消费者宕机了，内存队列里面还未消费的消息也就丢了。



假设1W个消息积压在mq中。rabbitmq如果设置了ttl就会使消息过期丢失。解决方法：不要设ttl。或者手动写程序查出丢失消息，手动写入mq。

将所有的consumer暂停，临时征用20倍的机器，建立20倍数量的queue，写一个临时的consumer，把积压的消息轮询写入20倍的queue中，然后进行消费。

mq满了怎么办？写新的消费者，不处理消息，快速消费掉。空闲时再补。

1. 一致性问题？

    系统ABCD中，AB执行成功了，CD执行失败，导致一致性问题



---



# 设计一个消息队列

1mq需要支持可伸缩性，在需要的时候快速扩容，增加吞吐量和容量。 

设计一个分布式的系统

* 持久化   **将消息暂时buffer起来**,当消息的个数(或尺寸)达到一定阀值时,再flush到磁盘,这样减少了磁盘IO调用的次数.   **磁盘顺序读写，**没有磁盘随机读写的寻址开销，提高性能
* 可用性  高可用机制，多副本，leader挂了重新选举leader即可对外服务

数据传输可靠性   

































