# 消息队列的作用：

**异步：**

* 同步操作需要等待。一些非必要的业务逻辑可以用异步操作，节约时间。
* 和线程池有什么区别：线程池需要进行对线程进行管理，需要有较大的代码变动
* 随着项目的**请求链路越来越长**，会越来越慢。

**削峰：**

* 让系统按照处理速度慢慢从消息队列拉取消息处理，这种短暂的消息积压是有必要的。

**解耦：**

* 子系统之间解耦，接入新的子系统无需修改原来的代码。
* 传统的软件开发模式，模块之间的调用是直接调用，这样的系统很不利于系统的扩展，同时，模块之间的相互调用，数据之间的共享问题也很大，每个模块都要时时刻刻考虑其他模块会不会挂了；
* 使用消息队列以后，模块之间不直接调用，而是通过数据，且当某个模块挂了以后，数据仍旧会保存在消息队列中。

---

# 消息队列组件

- rocketmq-client：提供发送、接受消息的客户端API。
- rocketmq-namesrv：类似于Zookeeper，**这里保存着消息的TopicName，队列等运行时的元信息**。
- rocketmq-broker：**接受生产者发来的消息并存储**（通过调用rocketmq-store），**消费者从这里取得消息**
- rocketmq-common：**通用的一些类，方法，数据结构**等。
- rocketmq-remoting：基于Netty4的client/server + fastjson**序列化 + 自定义二进制协议**。
- rocketmq-store：**消息、索引存储**等。
- rocketmq-filtersrv：**消息过滤器Server**，需要注意的是，要实现这种过滤，需要上传代码到MQ！（一般而言，我们利用Tag足以满足大部分的过滤需求，如果更灵活更复杂的过滤需求，可以考虑filtersrv组件）。
- rocketmq-tools：命令行工具。

---

## Name-server

**NameServer主要提供两个功能：Broker管理 和 路由信息管理**

* 压力不会太大，平时主要开销是在**维持心跳**和**提供Topic-Broker的关系数据**。
* 每个 Broker 在启动时会到 NameServer 注册，**运行期间Broker向NameServer发心跳时， 会带上当前broker所有Topic信息**
    * 如果**Topic**个数太多（万级别），心跳中topic信息会很大
    * 在网络差情况的情况下，心跳失败，导致NameServer误认为Broker心跳失败。

**NameServer** 被设计成几乎**无状态**的，**可以横向扩展**，**节点之间相互之间无通信，通过部署多台机器来标记自己是一个伪集群**。

* **Producer** 在发送消息前会**根据 Topic 到 NameServer 获取到 Broker 的路由信息**，
* **Consumer** 也会定时获取 Topic 的路由信息。

---

## Broker

消息中转角色，负责**存储消息（消息队列的高可用存储）**，**转发消息**。

- **Broker与所有的NameServer节点保持长连接及心跳，并会定时将Topic信息注册到NameServer**
    - 底层通信和连接都是**基于Netty实现**的。
- **Broker**负责以Topic为纬度的消息存储，具有**上亿级消息堆积能力**，同时可**严格保证消息的有序性**
    - RocketMQ Broker中的消息被消费后会立即删除吗？
        - 不会，每条消息都会**持久化到CommitLog**中，
        - 每个Consumer连接到Broker后会维持消费进度信息，**当有消息被消费后只是当前Consumer的消费进度（CommitLog的offset）更新了**。

**怎么提高并发与高可用**：

* **一个 Topic 分布在多个 Broker上，一个 Broker 可以配置多个 Topic** ，它们是多对多的关系。
* 如果某个 Topic 消息量很大，应该给它多配置几个队列，并且 尽量多分布在不同 Broker 上，以减轻某个 Broker 的压力 。

![image-20210314164331491](http://haoimg.hifool.cn/img/image-20210314164331491.png)

---

## producer

**消息由Producer通过多种负载均衡模式发送到Broker集群**，发送低延时，支持快速失败。

- **同步发送**：同步发送指消息**发送方发出数据后会在收到接收方发回响应之后才发下一个数据包**。
    - 一般用于重要通知消息，例如重要通知邮件、营销短信。
- **异步发送**：异步发送指**发送方发出数据以及回调函数后，不等接收方发回响应，接着发送下个数据包**，
    - 一般用于可能链路耗时较长而对响应时间敏感的业务场景，例如用户视频上传后通知启动转码服务。
    - **发送方通过回调接口接收服务端响应，并处理响应结果。**
- **单向发送**：单向发送是指只负责**发送消息而不等待服务器回应，且没有回调函数触发**，
    - 适用于某些耗时非常短但对可靠性要求并不高的场景，例如日志收集。

![image-20210316142523719](http://haoimg.hifool.cn/img/image-20210316142523719.png)

---

## consumer

Consumer 提供**实时的消息订阅机制**

**Consumer**支持PUSH和PULL两种消费模式

- **Pull**：**Consumer主动**从消息队列拉取。
- **Push**：消息由**消息队列推送至Consumer**。
    - 封装了消息的拉取、消费进度和其他的内部维护工作，将消息到达时执行的回调接口留给用户应用程序来实现。
    - pus 实际底层实现采用的是**长轮询机制**，即拉取方式
    - 不同于 Pull 的是 Push 首先要注册消费监听器，当监听器处触发后才开始消费消息。



**为什么要主动拉取消息而不使用事件监听方式？**

* 事件驱动方式是建立好**长连接**，由事件（发送数据）的方式来实时推送。
* 如果broker主动推送消息的话有可能**push速度快，消费速度慢**的情况，那么就会造成消息在consumer端堆积消息过多，同时又不能被其他consumer消费的情况。
* 而pull的方式可以根据当前自身情况来pull，不会造成过多的压力而造成瓶颈。
* 所以采取了pull的方式。



**Consumer**支持**集群消费**和**广播消息**

* **Clustering（集群消费）**：同一个Group ID所标识的所有Consumer平均分摊消费消息，一条消息只会被同Group中的一个Consumer消费。
    * 例如某个Topic有9条消息，一个Group ID有3个Consumer实例，那么在集群消费模式下每个实例平均分摊，只消费其中的3条消息。
    * 多个Group同时消费一个Topic时，每个Group都会有一个Consumer消费到数据
* **Broadcasting（广播消费）**：同一个Group ID所标识的所有Consumer都会各自消费某条消息一次。
    * 例如某个Topic有9条消息，一个Group ID有3个Consumer实例，那么在广播消费模式下每个实例都会各自消费9条消息。

---

## 消息队列集群部署

![image-20210314164850429](http://haoimg.hifool.cn/img/image-20210314164850429.png)

1. **`Broker` 做了集群并且还进行了主从部署** ，
    * 消息存储在各个 `Broker` 上，一旦某个 `Broker` 宕机，则该`Broker` 上的消息读写都会受到影响。
    *  `Rocketmq` 提供了 `master/slave` 的结构，**` salve` 定时从 `master` 同步数据(同步刷盘或者异步刷盘)**，如果 `master` 宕机，**则 `slave` 提供消费服务，但是不能写入消息**。
2. **`NameServer` 去中心化集群部署**，**没有主节点**，
    * 在 `RocketMQ` 中是通过 **单个Broker和所有NameServer保持长连接** ，
    * 每隔30秒 `Broker` 会向所有 `Nameserver` 发送心跳（Routing Info），心跳包含了自身的 `Topic` 配置信息 。
3. **生产者**
    * producer 向`Broker` 发送消息的时，**先从 `NameServer` 获取关于 `Broker` 的路由信息**，
    * 然后 producer 通过 **轮询** 的方法去向每个队列中生产数据以达到 **负载均衡** 的效果。
4. **消费者**
    * consumer 通过 `NameServer` 获取所有 `Broker` 的路由信息后，向 `Broker` 发送 `Pull` 请求来获取消息数据。

---

# 消息领域模型

![image-20210302132644963](http://haoimg.hifool.cn/img/image-20210302132644963.png)

---

## Message

**Message**（消息）就是要传输的信息。

* 一条消息必须有一个主题（Topic），主题可以看做是你的信件要邮寄的地址。
* 一条消息也可以拥有一个可选的标签（Tag）和额处的键值对，它们可以用于设置一个业务 Key 并在 Broker 上查找此消息以便在开发期间查找问题。

---

## Topic

![image-20210314161929870](http://haoimg.hifool.cn/img/image-20210314161929870.png)

**Topic**（主题）可以看做消息的规类，它是消息的第一级类型。

* **Topic** 与生产者和消费者的关系非常松散，是多对多的关系。

**一个主题中存在多个队列，生产者每次生产消息之后是指定主题中的某个队列发送消息的。**

* **集群消费模式下**，**一个消费者集群中的多个消费者共同消费一个 topic 的多个队列，一个队列只会被一个消费者消费。**
* 如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。
* 就像上图中 Consumer1 和 Consumer2 分别对应着两个队列，而 Consuer3 是没有队列对应的，所以一般来讲要控制 **消费者组中的消费者个数和主题中队列个数相同** 。

---

## Tag

**Tag**（标签）可以看作子主题，它是消息的第二级类型，用于为用户提供额外的灵活性。

使用标签，同一业务模块不同目的的消息就可以用相同 Topic 而不同的 **Tag** 来标识。

比如交易消息又可以分为：交易创建消息、交易完成消息等，一条消息可以没有 **Tag** 。

标签有助于保持您的代码干净和连贯，并且还可以为 **RocketMQ** 提供的查询系统提供帮助。

---

## Group

**分组，一个组可以订阅多个Topic**。

* 一个组中的消费者，同时只能访问一个队列，多个消费者不可以同时访问一个队列。

---

## Queue

在**Kafka**中叫Partition，每个Queue内部是有序的

在**RocketMQ**中分为读和写两种队列，一般来说读写队列数量一致，如果不一致就会出现很多问题。

---

## Message Queue

![image-20210314163519000](http://haoimg.hifool.cn/img/image-20210314163519000.png)

**Message Queue**（消息队列），消息的物理管理单位。**一个Topic下可以有多个Queue**，Queue的引入使得消息的存储可以分布式集群化，具有了水平扩展能力。

**一个 Topic 下可以设置多个消息队列**，发送消息时执行该消息的 Topic ，RocketMQ 会轮询该 Topic 下的所有队列将消息发出去。

**为什么一个主题中需要维护多个队列 ？提高并发能力**

* 如果每个主题中只存在一个队列，这个队列中也维护着每个消费者组的消费位置，这样也可以做到 发布订阅模式 
* 但是，这样我生产者只能向一个队列发送消息，又因为**需要维护消费位置**，所以**一个队列只能对应一个消费者组中的消费者**，这样是不是**其他的 Consumer 就闲置了**？从这两个角度来讲，并发度一下子就小了很多。
* 所以，**RocketMQ 通过使用在一个 Topic 中配置多个队列**，并且**每个队列维护每个消费者组的消费位置**，实现了 主题模式/发布订阅模式 。

---

## Offset

![image-20210314162925411](http://haoimg.hifool.cn/img/image-20210314162925411.png)

在**RocketMQ** 中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是指队列中的每个存储单元都是定长，访问其中的存储单元使用Offset 来访问，Offset 为 java long 类型，64 位，理论上在 100年内不会溢出，所以认为是长度无限。

也可以认为 Message Queue 是一个长度无限的数组，**Offset** 就是下标。

**发布订阅模式中一般会涉及到多个消费者组**，而**每个消费者组在每个队列中的消费位置都是不同的**。

* 如果此时有多个消费者组，那么**消息被一个消费者组消费完之后是不会删除的**(因为其它消费者组也需要呀)，
* **消息队列为每个消费者组维护一个 消费位移(offset)** ，每次消费者组消费完会返回一个成功的响应，然后队列再把维护的消费位移**加一**，**这样就不会出现刚刚消费过的消息再一次被消费了**。

---

## Message Order

**Message Order**（消息顺序）有两种：**Orderly**（顺序消费）和**Concurrently**（并行消费）。

顺序消费表示消息消费的顺序同生产者为每个消息队列发送的顺序一致，所以如果正在处理全局顺序是强制性的场景，需要确保使用的主题只有一个消息队列。

并行消费不再保证消息顺序，消费的最大并行数量受每个消费者客户端指定的线程池限制。

---

# 面试可能会问道的问题

## 1 为什么使用消息队列？

**异步：**

* 同步操作需要等待。一些非必要的业务逻辑可以用异步操作，节约时间。

**削峰：**

* 大量请求直接打到redis或者DB上，压力过大。
* 让系统按照处理速度慢慢从消息队列拉取消息处理，实现信息的最终一致性，这种短暂的消息积压是有必要的。

**解耦：**

* 子系统之间解耦，接入新的子系统无需修改原来的代码。
* 传统的软件开发模式，模块之间的调用是直接调用，这样的系统很不利于系统的扩展，同时，模块之间的相互调用，数据之间的共享问题也很大，每个模块都要时时刻刻考虑其他模块会不会挂了；
* 使用消息队列以后，模块之间不直接调用，而是通过数据，且当某个模块挂了以后，数据仍旧会保存在消息队列中。

**秒杀系统主要是为了削峰**

---

## 2 消息队列在使用过程中的问题？

- 系统**可用性降低**：**消息队列挂了，系统也会挂掉。**
- 如何保证消息**不丢失**？如何保证消息的可靠性传输。
- 如何保证消息**按顺序消费**？
- 如何保证消息**不被重复消费**？
- **如何解决消息积压问题？**



**加分问题：**

1. 组件通信间使用 Netty 的自定义协议
2. 消息重试负载均衡策略（具体参考 Dubbo 负载均衡策略）
3. 消息过滤器（Producer 发送消息到 Broker，Broker 存储消息信息，Consumer 消费时请求 Broker 端从磁盘文件查询消息文件时,在 Broker 端就使用过滤服务器进行过滤）
4. Broker 同步双写和异步双写中 Master 和 Slave 的交互
5. Broker 在 4.5.0 版本更新中引入了 基于 Raft 协议的多副本选举，之前这是商业版才有的特性 [ISSUE-1046](http://rocketmq.apache.org/release_notes/release-notes-4.5.0/)
6. 事务一致性问题？
    1. 系统ABCD中，AB执行成功了，CD执行失败，导致一致性问题

---

## 3 各个消息队列对比？

1. Kafka技术通常是在大数据的实时数据计算领域，**模型简单，qps高，但是会有消息重复消费**问题。
    1. Scala开发，面向日志功能丰富，性能最高。
    2. 当你的业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。
    3. 所以，Kafka 不太适合在线业务场景。
2. RabbitMq 用erlang写的，有四种发布订阅模型，缺点是**吞吐量不高，且不是分布式mq**。
    1. 对消息堆积的支持并不好，当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降。
    2. 每秒钟可以处理几万到十几万条消息。
3. RocketMq 是阿里开源的组件，用java写的，吞吐量高，社区活跃度低于RabbitMq。

---

## 4 * 如何保证消息队列是高可用的？

**引入mq会导致可用性降低，mq一旦挂掉，系统也会挂掉。**

**集群法：NameServer 集群、Broker 集群、Producer 集群和 Consumer 集群：**

* NameServer: 提供轻量级的服务发现和路由。 
    * 每个 NameServer 记录完整的路由信息，提供等效的读写服务，并支持快速存储扩展。
* Broker: 通过提供轻量级的 Topic 和 Queue 机制来处理消息存储,同时支持推（push）和拉（pull）模式以及主从结构的容错机制。
    * 同时每个 Broker 与NameServer 集群中的所有节点建立长连接，定时注册 Topic 信息到所有 NameServer 中。
    * 集群中broker之间会进行数据同步
* Producer：生产者，产生消息的实例，拥有相同 Producer Group 的 Producer 组成一个集群。
    * Producer 与 NameServer 集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer 获取 Topic 路由信息，
    * Producer 并向提供 Topic 服务的 Broker Master 建立长连接，且定时向 Broker 发送心跳。
* Consumer：消费者，接收消息进行消费的实例，拥有相同 Consumer Group 的Consumer 组成一个集群。
    * Producer 只能将消息发送到 Broker master，
    * Consumer 则不一样，它同时和提供 Topic 服务的 Master 和 Slave 建立长连接，既可以从 Broker Master 订阅消息，也可以从 Broker Slave 订阅消息。



**RocketMQ的集群方式为：**

* 多个master集群
    * 全是Master，无Slave。某个实例挂了，该实例在重启前未被消费的消息无法被消费
        * 优点：配置简单，性能最高
        * 缺点：单台机器重启或宕机期间，该机器下未被消费的消息在机器恢复前不可订阅，影响消息实时性
* 多Master多Slave模式-异步复制（一般生产环境使用））
    * 每个Master配一个Slave，有多对Master-Slave，集群采用异步复制方式，主备有短暂消息延迟，毫秒级
    * 优点：性能同多Master几乎一样，实时性高，主备间切换对应用透明，不需人工干预
    * 缺点：Master宕机或磁盘损坏时会有少量消息丢失
* 多Master多Slave模式-同步双写（对数据可靠性要求高时使用）
    * 每个Master配一个Slave，有多对Master-Slave，集群采用同步双写方式，主备都写成功，才向应用返回成功
        * 优点：服务可用性与数据可用性非常高
        * 缺点：性能比异步集群略低（大约低10%），当前版本主宕备不能自动切换为主
        * 类似于mysql的主从概念，Master挂了以后，Slave仍然可以提供读服务，但是由于有多主的存在，当一个Master挂了以后，可以写到其他的Master上。

![img](http://haoimg.hifool.cn/img/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NoZW5nSHVhbkh1YW5pbmc=,size_16,color_FFFFFF,t_70.png)

rabbitmq：

* rabbitmq是一个**非分布式MQ**，基于主从模式做高可用。
* **普通集群模式**：queue存放在一个节点，其他节点只有queue的元数据（配置信息），如果访问了其他节点，就会去queue所在节点拉数据。
* **镜像集群模式**：queue的元数据和消息都存在与所有节点，每次写数据都进行同步。消费消息时，ack消息通过循环链表发送，每个queue都要消除缓存消息。  坏处：开销大

kafka的高可用：（感觉好像是Raft啊）

* 生产者往leader里写数据
* leader把数据同步到follwer。
* 消费者消费leader的数据。
* leader挂掉则选举出新的leader

---

## 5 如何保证消费的可靠性传输？

要保证可靠传输，需要从生产者，消费者，消息队列三个方面考虑。

**生产者写消息过程需要有确认机制：**

* 生产者（Producer） 通过网络发送消息给 Broker，当 Broker 收到之后，将会返回确认响应信息给 Producer。所以生产者只要接收到返回的确认响应，就代表消息在生产阶段未丢失。
* 同步：消息发送成功仅代表消息已经到了 Broker 端，Broker 在不同配置下，可能会返回不同响应状态:
    - ![image-20200319220927210](http://haoimg.hifool.cn/img/1419561-20200325081448381-295017799.jpg)
* 异步：RocketMQ 还提供异步的发送的方式，适合于链路耗时较长，对响应时间较为敏感的业务场景。
    - 异步发送消息一定要**注意重写**回调方法，在回调方法中检查发送结果。
* 不管是同步还是异步的方式，都会碰到网络问题导致发送失败的情况。
    * 针对这种情况，我们可以设置合理的重试次数，当出现网络问题，可以自动重试。

**存储阶段：**

* 默认情况下，消息只要到了 Broker 端，将会优先保存到内存中，然后立刻返回确认响应给生产者。随后 Broker 定期批量的将一组消息从内存异步刷入磁盘。
* 这种方式减少 I/O 次数，可以取得更好的性能，但是如果发生机器掉电，异常宕机等情况，消息还未及时刷入磁盘，就会出现丢失消息的情况。
* 若想保证 Broker 端不丢消息，保证消息的可靠性，我们**需要将消息保存机制修改为同步刷盘方式**，即消息**存储磁盘成功**，才会返回响应。
* 若 Broker 未在同步刷盘时间内（**默认为 5s**）完成刷盘，将会返回 `SendStatus.FLUSH_DISK_TIMEOUT` 状态给生产者。
* **集群部署：**
    * 为了保证可用性，Broker 通常采用一主（**master**）多从（**slave**）部署方式。
    * 为了保证消息不丢失，消息还需要复制到 slave 节点。
    * 默认方式下，消息写入 **master** 成功，就可以返回确认响应给生产者，接着消息将会异步复制到 **slave** 节点。
    * 此时若 master 突然**宕机且不可恢复**，那么还未复制到 **slave** 的消息将会丢失。
    * 为了进一步提高消息的可靠性，我们可以采用同步的复制方式，**master** 节点将会同步等待 **slave** 节点复制完成，才会返回确认响应。
    * 如果 **slave** 节点未在指定时间内同步返回响应，生产者将会收到 `SendStatus.FLUSH_SLAVE_TIMEOUT` 返回状态。



**消费阶段：**

* 消费者从 broker 拉取消息，然后执行相应的业务逻辑。一旦执行成功，将会返回 `ConsumeConcurrentlyStatus.CONSUME_SUCCESS` 状态给 Broker。
* 如果 Broker 未收到消费确认响应或收到其他状态，消费者下次还会再次拉取到该条消息，进行重试。这样的方式有效避免了消费者消费过程发生异常，或者消息在网络传输中丢失的情况。
* 以上消费消息过程的，我们需要**注意返回消息状态**。只有当业务逻辑真正执行成功，我们才能返回 `ConsumeConcurrentlyStatus.CONSUME_SUCCESS`。否则我们需要返回 `ConsumeConcurrentlyStatus.RECONSUME_LATER`，稍后再重试。



---

## 6 如何保证消息的顺序性？

[分析消息的有序性](https://dbaplus.cn/news-73-1123-1.html)

### 全局有序：

* **对于指定的一个Topic，所有消息按照严格的先入先出（FIFO）的顺序来发布和消费。**
* 如果要保证消息的全局有序，首先只能由一个生产者往Topic发送消息，并且**一个Topic内部只能有一个队列**（分区）。
* **消费者也必须是单线程消费这个队列**。这样的消息就是全局有序的！

**适用场景：**

* 适用于**性能要求不高，所有的消息严格按照FIFO原则**来发布和消费的场景。
    * 在证券处理中，以人民币兑换美元为Topic，在价格相同的情况下，先出价者优先处理，则可以按照FIFO的方式发布和消费全局顺序消息。
* 一般情况下我们都不需要全局有序



### 分区顺序消息：

* 绝大部分的有序需求是**部分有序**，部分有序我们就可以**将Topic内部划分成需要的队列数**，把消息通过特定的策略发往固定的队列中，**保证顺序性的消息写入同一个queue**
* 对于指定的一个Topic，所有消息根据Sharding Key进行区块分区。
    * 使用**Hash取模法**，让同一个订单发送到同一个队列中，
    * 再使用同步发送，只有同个订单的创建消息发送成功，再发送支付消息。这样，我们保证了发送有序。
* **同一个分区内的消息按照严格的FIFO顺序进行发布和消费**。
* **Sharding Key是顺序消息中用来区分不同分区的关键字段**，和普通消息的Key是完全不同的概念。
* 然后**每个队列对应一个单线程处理的消费者**。
* 这样即完成了部分有序的需求，又可以**通过队列数量的并发来提高消息处理效率**。

**适用场景：**

* **适用于性能要求高，以Sharding Key作为分区字段，在同一个区块中严格地按照FIFO原则进行消息发布和消费的场景。**
    * 用户注册需要发送发验证码，以用户ID作为Sharding Key，那么同一个用户发送的消息都会按照发布的先后顺序来消费。
    * 电商的订单创建，以订单ID作为Sharding Key，那么同一个订单相关的创建订单消息、订单支付消息、订单退款消息、订单物流消息都会按照发布的先后顺序来消费。

![image-20210305191536295](http://haoimg.hifool.cn/img/image-20210305191536295.png)



![image-20210310211229859](http://haoimg.hifool.cn/img/image-20210310211229859.png)



### 使用顺序消息注意事项

- 建议**同一个Group ID只对应一种类型的Topic**，即不同时用于顺序消息和无序消息的收发。
- 对于**全局顺序消息，建议消息不要有阻塞**。
    - 同时运行多个实例，是为了防止工作实例意外退出而导致业务中断。
    - 当工作实例退出时，其他实例可以立即接手工作，不会导致业务中断，实际工作的只会有一个实例。

### 顺序消息常见问题

- **同一条消息是否可以既是顺序消息，又是定时消息和事务消息？**
    * **不可以。**
    * 顺序消息、定时消息、事务消息**是不同的消息类型**，三者是互斥关系，不能叠加在一起使用。
- **为什么全局顺序消息性能一般？**
    * 全局顺序消息是严格按照FIFO的消息阻塞原则，即上一条消息没有被成功消费，下一条消息会一直被存储到Topic队列中。
    * 如果想提高全局顺序消息的TPS，可以升级实例配置，同时消息客户端应用尽量减少处理本地业务逻辑的耗时。
- **顺序消息支持哪种消息发送方式？**
* 顺序消息**只支持可靠同步发送方式**，不支持异步发送方式，否则将无法严格保证顺序。
- **顺序消息是否支持集群消费和广播消费？**
* **顺序消息暂时仅支持集群消费模式**，不支持广播消费模式。

---

## 7 * 如何保证消息不被重复消费/幂等性？

幂等

* 同样的参数多次调用同一个接口和调用一次产生的结果是一致的。

**消息重复的场景如下：**

- 发送时消息重复

    * 当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败。 
* 如果此时生产者意识到消息发送失败并尝试再次发送消息，消费者后续会收到两条内容相同并且Message ID也相同的消息。
- 投递时消息重复

    * 消息消费的场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。
* 为了保证消息至少被消费一次，消息队列RocketMQ版的服务端将在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且Message ID也相同的消息。
- 负载均衡时消息重复（包括但不限于网络抖动、Broker重启以及消费者应用重启）
- 当消息队列RocketMQ版的Broker或客户端重启、扩容或缩容时，会触发Rebalance，此时消费者可能会收到重复消息。



可能的解决方法：

1. 消费端：处理消息的业务逻辑保持幂等性，处理过的orderID不再进行处理
2. 消息队列中间件：保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现
    * 第2条可以消息系统实现，也可以业务端实现。
    * 正常情况下出现重复消息的概率其实很小，如果由消息系统来实现的话，肯定会对消息系统的吞吐量和高可用有影响，所以最好还是由业务端自己处理消息重复的问题，这也是RocketMQ不解决消息重复的问题的原因。
    * RocketMQ不保证消息不重复，如果你的业务需要保证严格的不重复消息，需要你自己在业务端去重。
    * 最简单的解决方案是**每条消费记录有个消费状态字段**，根据这个消费状态字段来是否消费或者使用一个集中式的表，来**存储所有消息的消费状态，从而避免重复消费**



因为Message ID有可能出现冲突（重复）的情况，所以真正安全的幂等处理，不建议以Message ID作为处理依据。

最好的方式是以业务唯一标识作为幂等处理的关键依据，而业务的唯一标识可以通过消息Key设置。

以支付场景为例，可以将消息的Key设置为订单号，作为幂等处理的依据。具体代码示例如下：

```java
Message message = new Message();
message.setKey("ORDERID_100");
SendResult sendResult = producer.send(message);           
```

消费者收到消息时可以根据消息的Key，即订单号来实现消息幂等：

```java
consumer.subscribe("ons_test", "*", new MessageListener() {
    public Action consume(Message message, ConsumeContext context) {
        String key = message.getKey()
        // 根据业务唯一标识的Key做幂等处理
    }
});        
```



保证消息幂等性，需要结合具体的业务来讨论。

* **Mysql**：
    * 如果是对mysql **insert**操作
        * 做一个**唯一的主键**，出现重复消费就会导致主键冲突，然后事务回滚。避免数据库出现**脏数据**。
    * 如果是对mysql **update**操作
        * 那么加个**version**字段做版本控制。

* 如果是**redis**，
    * 那么set操作天然就是幂等性的。
* 如果是**更复杂的业务场景**
    * 根据APPname，接口名，主机名创建一个全局幂等id存入redis，或者内存set，或者数据库的幂等表中，
    * 每次先进行幂等性判断。
* 在实习的津贴项目中
    * 针对幂等性的解决方案是设计一个**幂等表**，
    * 核心业务逻辑都需要**先通过幂等ID查幂等表，保证幂等性**。

---

## 8 * 如何解决一条消息能被多次消费？

`RabbitMQ` 就是采用队列模型

* 通过 `Exchange` 模块来将消息发送至多个队列，解决一条消息需要被多个消费者消费问题。
* 通过多队列全量存储相同的消息，即数据的冗余可以实现一条消息被多个消费者消费。

发布/订阅模型

* 该模型是将消息发往一个Topic即主题中，
* 所有订阅了这个 Topic 的订阅者都能消费这条消息。

发布订阅模型

* 为让一条消息可以被多个消费者消费

队列模型

* 队列模型每条消息只能被一个消费者消费
* 队列模型也可以通过消息全量存储至多个队列来解决一条消息被多个消费者消费问题，但是会有数据的冗余。

---

## 9 消息堆积 + 延迟问题怎么办？

消息的堆积往往是因为**生产者的生产速度与消费者的消费速度不匹配**。

* 可能是因为消息消费失败反复重试造成的，
* 可能是消费者消费能力弱，渐渐地消息就积压了。
    * 消息堆积的主要瓶颈在于本地客户端的消费能力，即**消费耗时**和**消费并发度**。
    * 想要避免和解决消息堆积问题，必须合理的**控制消费耗时 和 消息并发度**，
    * 其中**消费耗时的优先级高于消费并发度**，必须先保证消费耗时的合理性，再考虑消费并发度问题。

因此我们需要**先定位消费慢的原因**，

* 如果是`bug`则处理 `bug` ，如果是因为本身消费能力较弱，
* 我们可以优化下消费逻辑，比如之前是一条一条消息消费处理的，这次我们批量处理，比如数据库的插入，一条一条插和批量插效率是不一样的。

**假如逻辑我们已经都优化了，但还是慢，暂时进行水平扩容**

* 那就得考虑水平扩容了，增加`Topic`的队列数和消费者数量，
    1. 先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉。
    2. 新建一个topic，临时建立好原先10倍或者20倍的queue数量。
    3. 然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue。
    4. 接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据。
    5. 这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据。
    6. 等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息。
* **注意队列数一定要增加**，不然新增加的消费者是没东西消费的。
* **一个Topic中，一个队列只会分配给一个消费者**。



**长远来看得从消费耗时+消费并发度的角度解决问题**

**消费耗时：**

* 影响消费耗时的消费逻辑主要分为**CPU内存计算**和**外部I/O操作**
* 通常情况下代码中如果没有复杂的递归和循环的话，内部计算耗时相对外部I/O操作来说几乎可以忽略。
* 外部I/O操作通常包括如下业务逻辑：
    - 读写外部数据库，例如Mysql数据库读写。
    - 读写外部缓存等系统，例如Redis读写。
    - 下游系统调用，例如Dubbo调用或者下游HTTP接口调用。
        - 消费堆积首先要判断消费逻辑中I/O操作的耗时是否合理。
        - 通常消费堆积都是由于这些下游系统出现了服务异常、容量限制导致的消费耗时增加。

**消费并发度：**

* 客户端消费并发度由**单节点线程数**和**节点数量**共同决定，

* 一般情况下需要**优先调整单节点的线程数**，若单机硬件资源达到上限，则必须通过**扩容节点**来提高消费并发度。

    * 单机vCPU核数为C。

    * 线程切换耗时忽略不计，I/O操作不消耗CPU。

    * 线程有足够消息等待处理，且内存充足。

    * 逻辑中CPU计算耗时为T1，外部I/O操作为T2。

    * 则单个线程能达到的TPS为1/（T1+T2），如果CPU使用率达到理想状态100%，那么单机达到最大能力时需要设置线程数
        $$
        C*(T1+T2)/T1
        $$

---

## 10 回溯消费消息

回溯消费是指 `Consumer` 已经消费成功的消息，由于业务上需求需要重新消费

* 在`RocketMQ` 中， `Broker` 在向`Consumer` 投递成功消息后，**消息仍然需要保留** 。
* 并且重新消费一般是按照时间维度，例如由于 `Consumer` 系统故障，恢复后需要重新消费1小时前的数据，那么 `Broker` 要提供一种机制，可以按照时间维度来回退消费进度。
* `RocketMQ` 支持按照时间回溯消费，时间维度精确到毫秒。 

---

## 11 RocketMQ的刷盘机制

### 1 同步刷盘和异步刷盘

**刷盘是将消息从缓存中取出来，存储到文件中**

![image-20210314203816862](http://haoimg.hifool.cn/img/image-20210314203816862.png)

**同步刷盘：**

* 同步刷盘中需要等待一个刷盘成功的 `ACK`，
* 同步刷盘对 `MQ` 消息可靠性来说是一种不错的保障，但是 **性能上会有较大影响** ，一般地适用于金融等特定业务场景。
* **同步落盘怎么才能快？**
    1. 使用 FileChannel + DirectBuffer 池，**使用堆外内存，加快内存拷贝**
    2. **使用数据和索引分离**，当消息需要写入时，使用 commitlog 文件顺序写，当需要定位某个消息时，查询index 文件来定位，从而减少文件IO随机读写的性能损耗



**异步刷盘：**

* 异步刷盘往往是开启一个线程去**异步地执行刷盘操作**。
    * 消息刷盘采用后台异步线程提交的方式进行， **降低了读写延迟 ，提高了 `MQ` 的性能和吞吐量**，
    * 一般适用于如发验证码等对于消息保证要求不太高的业务场景。
* **异步刷盘只有在 `Broker` 意外宕机的时候会丢失部分数据**
    * 设置 `Broker` 的参数 `FlushDiskType` 来调整你的刷盘策略(ASYNC_FLUSH 或者 SYNC_FLUSH)。

---

### 2 同步复制和异步复制

**同步刷盘和异步刷盘是在单个结点层面**的，而同步复制和异步复制主要是指的 **`Borker` 在 master/slave 模式下，主节点返回消息给客户端的时候是否需要同步从节点**。

- 同步复制： 也叫 “同步双写”，也就是说，**只有消息同步双写到 主+从 结点上时才返回写入成功** 。
    - 如果Master出故障，Slave上有全部的备份数据，容易恢复，但是同步复制会增大数据写入延迟，降低系统吞吐量。
- 异步复制： **消息写入主节点之后就直接返回写入成功** 。
    - 如果Master出了故障，有些数据因为没有被写 入Slave，有可能会丢失；



**总结推荐：**

* **Master 和 Slave 的刷盘方式 设置成ASYNC_FLUSH的异步刷盘方式，**
* **Master 和 Slave 之间配置成SYNC_MASTER的同步复制方式，**这样即使有一台机器出故障，仍然可以保证数据不丢。



**异步复制会不会也像异步刷盘那样影响消息的可靠性呢？**

* **不会的**
* 因为两者是不同的概念，对于**消息可靠性是通过不同的刷盘策略保证**的，而像异步同步复制策略仅仅是影响到了 **可用性** 。
* 为什么呢？其主要原因**是 `RocketMQ` 是不支持自动主从切换的，当主节点挂掉之后，生产者就不能再给这个主节点生产消息了**。
* 比如这个时候采用异步复制的方式，在主节点还未发送完需要同步的消息的时候主节点挂掉了，这个时候从节点就少了一部分消息。
* 但是此时**生产者无法再给主节点生产消息**了，**消费者可以自动切换到从节点进行消费**(仅仅是消费)，所以在主节点挂掉的时间只会产生主从结点短暂的消息不一致的情况，降低了可用性，
* 当主节点重启之后，**从节点那部分未来得及复制的消息还会继续复制。**

在单主从架构中，如果一个主节点挂掉了，那么也就意味着整个系统不能再生产了。那么这个可用性的问题能否解决呢？**一个主从不行那就多个主从的呗**，别忘了在我们最初的架构图中，每个 `Topic` 是分布在不同 `Broker` 中的。

[![img](http://haoimg.hifool.cn/img/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d31312f313665663338363837343838613561342e6a7067.jpeg)](https://camo.githubusercontent.com/23fdbe0613b587ade69b1f6527ce77d472bb5e35da1afa4d8eff4dd398efc143/68747470733a2f2f6d792d626c6f672d746f2d7573652e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f323031392d31312f313665663338363837343838613561342e6a7067)

但是这种复制方式同样也会带来一个问题，那就是无法保证 **严格顺序** 。在上文中我们提到了**如何保证的消息顺序性是通过将一个语义的消息发送在同一个队列中，使用 `Topic` 下的队列来保证顺序性的**。如果此时我们主节点A负责的是订单A的一系列语义消息，然后它挂了，这样其他节点是无法代替主节点A的，如果我们任意节点都可以存入任何消息，那就没有顺序性可言了。

而在 `RocketMQ` 中采用了 **`Dledger`** 解决这个问题。他要求在写入消息的时候，要求**至少消息复制到半数以上的节点之后**，才给客⼾端返回写⼊成功，并且它是**⽀持通过选举来动态切换主节点**的。这里我就不展开说明了，读者可以自己去了解。

> 也不是说 `Dledger` 是个完美的方案，至少在 `Dledger` 选举过程中是无法提供服务的，而且他必须要使用三个节点或以上，如果多数节点同时挂掉他也是无法保证可用性的，而且要求消息复制板书以上节点的效率和直接异步复制还是有一定的差距的。

---

### 3 存储机制

1. 在 `Topic` 中的 **队列是以什么样的形式存在的？**
2. **队列中的消息又是如何进行存储持久化的呢？**

![image-20210314205814691](http://haoimg.hifool.cn/img/image-20210314205814691.png)

RocketMQ 消息存储架构中的三大角色：

1. **CommitLog** 
    * **消息主体以及元数据的存储主体**，存储 `Producer` 端写入的消息主体内容,消息内容不是定长的。
    * 消息主要是**顺序写入日志文件**，单个文件大小默认1G ，当文件满了，写入下一个文件。
        * 单个文件大小默认1G ，文件名长度为20位，左边补零，剩余为起始偏移量，
        * 比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；
        * 当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。
2. **ConsumeQueue**  
    * 消息消费队列，**引入的目的主要是提高消息消费的性能**，
        * `RocketMQ` 是基于主题 `Topic` 的**订阅模式**，
        * 消息消费是针对主题进行的，
        * 如果要遍历 `commitlog` 文件中根据 `Topic` 检索消息是非常低效的。
    * `ConsumeQueue`（逻辑消费队列）**作为消费消息的索引**，**`Consumer` 即可根据 `ConsumeQueue` 来查找待消费的消息。**
        * `consumequeue` 文件可以看成是基于 `topic` 的 `commitlog` 索引文件
        * `ConsumeQueue` 保存了指定 `Topic` 下的队列消息在 `CommitLog` 中的
            * **起始物理偏移量 `offset`，**
            * **消息大小 `size` **
            * **消息 `Tag` 的 `HashCode` 值。**
3. **IndexFile** 
    * `IndexFile`（索引文件）提供了一种可以**通过key或时间区间来查询消息的方法**。

![image-20210314210000574](http://haoimg.hifool.cn/img/image-20210314210000574.png)





![image-20210314210040314](http://haoimg.hifool.cn/img/image-20210314210040314.png)

---

## 12 消息队列怎么做负载均衡？

**发布方消息负载均衡策略**

* RocketMQ版针对发布方采取的是轮询制，即Producer的消息以轮询的方式发送至Queue
* 发布方会把第一条消息发送至Queue 0，然后第二条消息发送至Queue 1，以此类推
* 分布式broker
    * 通过Topic在多Broker中分布式存储实现。
    * 提升写入吞吐量，当多个producer同时向一个broker写入数据的时候，性能会下降
    * 消息分布在多broker中，为负载消费做准备

![image-20210315152349099](http://haoimg.hifool.cn/img/image-20210315152349099.png)



**订阅方消息负载均衡策略：**

* RocketMQ包含Broker和Name Server等节点，其中Broker节点负责将Topic的路由信息上报至Name Server节点。
    * 假设目前消息队列RocketMQ版只有一个Broker节点，
    * 消息从Producer发送至RocketMQ的Topic，默认会将这些Topic下的消息均衡负载至8个Queue（逻辑概念）。
    * RocketMQ Broker会将这些Queue再平均分配至属于同一个Group ID的订阅方集群。

1. 若订阅方机器数量大于Queue的数量，则超出Queue数量的机器会处理0个Queue上的消息

    ![image-20210315152820964](http://haoimg.hifool.cn/img/image-20210315152820964.png)

2. 若订阅方机器数量等于Queue的数量，则每台机器会处理1个Queue上的消息

    ![image-20210315152848398](http://haoimg.hifool.cn/img/image-20210315152848398.png)

3. 若订阅方机器数量小于Queue的数量，则每台机器会处理多个Queue上的消息

    ![image-20210315152917762](http://haoimg.hifool.cn/img/image-20210315152917762.png)

如果其中一台机器处理变慢，可能是机器硬件、系统、远程RPC调用或Java GC等原因导致分配至此机器上的Queue的消息不能及时处理；此外，消息队列RocketMQ版的消息负载是按Queue为粒度维护，所以，整个Queue上的消息都会堆积



---

## 13 RocketMQ 事务消息

- **事务消息**：
    - RocketMQ提供类似X或Open XA的分布式事务功能，
    - 通过消息队列RocketMQ事务消息能达到**分布式事务的最终一致**。
- **半事务消息**：
    - **暂不能投递的消息**，发送方已经成功地将消息发送到了消息队列
    - 但是**服务端未收到生产者对该消息的二次确认**，此时该消息被**标记成“暂不能投递”状态**，处于该种状态下的消息即半事务消息。
    - 注：在事务提交之前，对于消费者来说，这个消息是不可见的 。
- **消息回查**：
    - 由于网络闪断、生产者应用重启等原因，**导致某条事务消息的二次确认丢失**，
    - **服务端通过扫描发现某条消息长期处于“半事务消息”时**，需要**主动向消息生产者询问该消息的最终状态**（Commit或是Rollback），该询问过程即消息回查。

**在 RocketMQ 中使用的是 事务消息 + 事务反查机制 来解决分布式事务问题的。**

![image-20210314202804680](http://haoimg.hifool.cn/img/image-20210314202804680.png)

**事务消息发送步骤如下：**

1. 发送方将半事务消息发送至消息队列服务端。
2. 服务端将消息持久化成功之后，向发送方返回Ack确认消息已经发送成功，此时消息为半事务消息。
3. 发送方开始执行本地事务逻辑。
4. 发送方根据本地事务执行结果向服务端提交二次确认（Commit或是Rollback），
    1. 服务端收到Commit状态则将半事务消息标记为可投递，订阅方最终将收到该消息；
    2. 服务端收到Rollback状态则删除半事务消息，订阅方将不会接受该消息。

**事务消息回查步骤如下：**

1. 在断网或者是应用重启的特殊情况下，上述步骤4提交的二次确认最终未到达服务端，经过固定时间后服务端将对该消息发起消息回查。
2. 发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。
3. 发送方根据检查得到的本地事务的最终状态再次提交二次确认，服务端仍按照步骤4对半事务消息进行操作。



**半事务消息如何做到写入消息但是对用户不可见呢？**

1. 如果消息是half消息，将备份原消息的主题与消息消费队列，然后 改变主题 为RMQ_SYS_TRANS_HALF_TOPIC。
2. 由于消费组未订阅该主题，故消费端无法消费half类型的消息，
3. 然后RocketMQ会开启一个定时任务，从Topic为RMQ_SYS_TRANS_HALF_TOPIC中拉取消息进行消费，
4. RocketMQ 根据生产者组获取一个服务提供者发送回查事务状态请求，根据事务状态来决定是提交或回滚消息。



**MQ的事务的最终一致性**

* 分布式事务结束之后，**MQ Server 指向系统B的操作已经和系统A不相关了**，
* 也就是说在消息队列中的分布式事务是——**本地事务和存储消息到消息队列才是同一个事务**。
* 这样也就产生了**事务的最终一致性**，因为整个过程是异步的，**每个系统只要保证它自己那一部分的事务就行了**。

---

# 设计一个消息队列

1mq需要支持可伸缩性，在需要的时候快速扩容，增加吞吐量和容量。 

设计一个分布式的系统

* 持久化   **将消息暂时buffer起来**,当消息的个数(或尺寸)达到一定阀值时,再flush到磁盘,这样减少了磁盘IO调用的次数.   **磁盘顺序读写，**没有磁盘随机读写的寻址开销，提高性能
* 可用性  高可用机制，多副本，leader挂了重新选举leader即可对外服务

数据传输可靠性   

































