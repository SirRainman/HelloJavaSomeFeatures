自我介绍：
尊敬的面试官您好，我叫冯辰昊。研究生就读于复旦大学计算机科学系，本科毕业于复旦大学环境科学与工程系。我的主语言是java，读过一些jdk源码，对java并发编程，jvm虚拟机也有一定的了解。此外，我还熟悉mysql，redis等数据库。今年6-8月，我在阿里巴巴天猫进出口事业群的考拉海购实习，主要负责考拉海购津贴部分的工作。我的主要工作内容分为三块，一是津贴系统的开发与优化，主要包括津贴前台系统和津贴后台系统。二是资损防控工作，主要包括在BCP业务校验平台编写校验规则，在BCP工程中为校验平台编写查询接口。三是迁移工程。在学校我主要参与的是Kubernetes和Openstack相关的项目。此外，我个人在业余时间也基于Springboot，redis，rabbitmq实现了一个秒杀系统。希望能有机会进入腾讯，在腾讯实现自我价值，谢谢。

最具挑战性的项目讲一下：

最具挑战性的项目我觉得还是在阿里实习过程中的津贴项目。因为其他的项目要么是自己写的demo，要么就是没有堆并发量没有要求的项目。而这个津贴项目是要抗住618，双十一的并发量的。一个难点就是项目能抗住多少并发量。618大促后台警报，因为并发量过大，solo缓存上触发限流，从而穿库到DB。经过排查，发现这是一个热Key问题。原来的key是schemeId，Value值是所有黑名单商品，所有并发集中在这个热key上，导致限流。然后做了一个临时解决方案，在本地加一个ConcurrentHashMap

实习中有意义的事情：
以津贴为例，津贴业务背景：购物津贴对标的竞品是天猫淘宝双十一购物津贴，采用购物津贴来贯穿整个大促期已经成为电商平台的主流做法。
由于购物津贴的设计就是在大促期使用，因此一个重要的关注点就是项目能抗住多少并发量。我对津贴后台工程针对并发量做了一个优化。原来的津贴黑名单存在热Key问题。原来的key值为schemeId，value为配置所有黑名单商品Id。这样会导致所有并发集中在这一个key上，引发solo限流，从而穿库。虽然后来又在本地用ConcurrentHashMap做缓存，但仍然存在风险隐患。最终的解决方案是拆分key。用商品Id做key，用true/false做value，彻底解决了这一问题。

工作：
首先简单介绍一下津贴项目，如图就是津贴项目的整体业务图
首先小二在后台创建津贴，BU和卖家报名参加津贴活动，在黑名单中剔除不参加活动的商品。然后小二将津贴活动发布上线。
买家通过前台的商品详情页，查看搜索结果，购物车，确定订单页，其他导购页向平台查询津贴生效信息，
提交订单页查询优惠金额，使用津贴。
发起退单后，询问卖家是否同意，卖家同意后如果有使用津贴优惠，就会回补津贴。最后买家收到货款。


kaola-allowance-compose 提供 查津贴标/领津贴/用津贴/退津贴/津贴明细查询/优惠金额计算等核心链路前台服务；
接下来介绍一下津贴的派发流程。津贴派发主要有津贴派发流程，津贴验证流程，计数校验流程，风控校验流程和数据持久化流程。
在津贴派发流程中，首先根据津贴ID，渠道ID，用户ID去获取分布式锁，获取失败的话就会直接返回操作太频繁。
接下来如果参数中事务ID不为空的话就会去查询幂等表，以保证幂等性，防止重复派发津贴。
接下来就会进入津贴验证流程，依次判断渠道ID，用户ID是否在黑名单，时间是否在活动时间。
接下来就会进入计数校验流程，这一流程主要是根据派发类型来生成津贴金额，然后依次校验总金额，每日限领金额，用户限领金额是否超过阈值。
接下来就会进入风控流程，调用风控提供的API。
接下来插入数据库，更新派发金额，更新账户余额，记录明细信息，写幂等表。
最后封装返回，并释放分布式锁。

