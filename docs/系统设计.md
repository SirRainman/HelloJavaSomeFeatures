

# 场景设计问题

高并发的度量指标一般有：

* QPS（每秒请求数，这个指标可归为系统吞吐率，一般QPS越高系统能hold住的请求数越多），
* RT（系统对一个请求做出响应的平均时间）。
* 并发数，
* qps和平均响应时间有这样的一道公式：QPS（TPS）= 并发数/平均响应时间。

![img](http://haoimg.hifool.cn/img/format,png-20210310170011804.jpeg)

大并发情景下可能会出现的问题：

* **缓存雪崩**
    * **设置缓存时采用了相同的过期时间**，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。
    * 解决方案：
        * **用加锁或者队列的方式保证缓存的单线 程（进程）写**，从而避免失效时大量的并发请求落到底层存储系统上。
* **缓存击穿**
    * 单一缓存key在某个时间点即将过期的时，突然有大量的并发请求查询该key，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
    * 和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。
    * 解决方案：[参考链接](https://blog.csdn.net/zeb_perfect/article/details/54135506)
        1. 使用互斥锁(mutex key)
        2. 提前"使用互斥锁(mutex key)：
        3. "永远不过期"：
        4. 资源保护：
* **缓存穿透**
    * **查询不存在的数据**，每次都要到存储层去查询，流量大时击垮DB
    * **布隆过滤器**：
        * 将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
* **超卖**
    * 卖的产品和上架的数量不一致
* **恶意请求**
    * 定价的抢票系统模拟请求
* **链接暴露**
    * 在开卖时间之前提前发出请求
    * 秒杀链接加盐：
        * 把URL动态化，就连写代码的人都不知道，通过MD5之类的摘要算法加密随机的字符串去做url，然后通过前端代码获取url后台校验才能通过。

---

## 解决高并发思路：

* **1.垂直方向扩展** 
    * 垂直方向主要做的就是提升单机能力
    * 硬件方向：花钱升级机器，更多核更高主频更大存储空间更多带宽
    * 软件方向：包括用各快的数据结构，改进架构，应用多线程、协程，以及上性能优化各种手段，
* **2.水平方向扩展**
    * 水平方向：分布式集群

这个理论上没有上限，只要做好层次和服务划分，加机器扩容就能满足需求，但实际上并非如此，一方面分布式会增加系统复杂性，另一方面集群规模上去之后，也会引入一堆AIOps、服务发现、服务治理的新问题。

因为垂直向的限制，所以，我们通常更关注水平扩展，高并发系统的实施也主要围绕水平方向展开。



**一些解决思路：**

* **限流：**
    * 监控应用流量的 QPS 或并发线程数等指标，**当达到指定的阈值时对流量进行控制，以避免被瞬时的流量高峰冲垮**，从而保障应用的高可用性。
    * 限流为了对服务端的接口接受请求的频率进行限制，防止服务挂掉。比如某一接口的请求限制为 100 个每秒, 对超过限制的请求放弃处理或者放到队列中等待处理。限流可以有效应对突发请求过多。相关阅读：[限流算法有哪些？](https://github.com/Snailclimb/JavaGuide/blob/master/docs/system-design/high-availability/limit-request.md)
    * 前端限流：按钮提前点击不能打开
    * 后端限流：请求有10W，我们不需要把十万都放进来，你可以放1W请求进来，然后再进行操作
* **降级：**
    * 降级是从**系统功能优先级的角度**考虑如何应对系统故障。
    * 服务降级指的是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此**释放服务器资源以保证核心任务的正常运行**。
    * 如果服务不可用了，返回一个兜底的处理方法。比如不让客户端等待立刻返回一个友好提示。
    * 出现降级的情况：
        - 程序运行异常
        - 超时
        - 服务熔断触发服务降级
        - 线程池/信号量打满
* **超时和重试机制设置**
    * 一旦用户请求超过某个时间的得不到响应，就抛出异常。
    * 在读取第三方服务的时候，尤其适合设置超时和重试机制。
    * 一般我们使用一些 RPC 框架的时候，这些框架都自带的超时重试的配置。如果不进行超时设置可能会导致请求响应速度慢，甚至导致请求堆积进而让系统无法在处理请求。
    * 重试的次数一般设为 3 次，再多次的重试没有好处，反而会加重服务器压力（部分场景使用失败重试机制会不太适合）。
* **熔断：**
    * **系统自动收集所依赖服务的资源使用情况和性能指标**，当所依赖的**服务恶化或者调用失败次数达到某个阈值的时候**就迅速失败，让当前系统**立即切换依赖其他备用服务**。 
    * 类比保险丝达到最大服务访问后，直接拒绝访问，拉闸限电，然后调用服务降级的方法返回友好提示。
    * 服务的降级 -> 进而熔断 -> 恢复调用链路
    * 比较常用的是流量控制和熔断降级框架是 Netflix 的 Hystrix 和 alibaba 的 Sentinel。
* **缓存**
    * 并发量比较高，当大量请求直接落到数据库可能数据库就会直接挂掉。
    * 使用缓存缓存热点数据，因为缓存存储在内存中，所以速度相当地快！
* **异步调用**
    * 异步调用的话我们不需要关心最后的结果，这样我们就可以用户请求完成之后就立即返回结果，具体处理我们可以后续再做，秒杀场景用这个还是蛮多的。
    * 除了可以在程序中实现异步之外，我们常常还使用消息队列，消息队列可以通过异步处理提高系统性能（削峰、减少响应所需时间）并且可以降低系统耦合性。

![image-20210314214804811](http://haoimg.hifool.cn/img/image-20210314214804811.png)

---

## 集群化：负载均衡

负载均衡就是把负载（request）均衡分配到不同的服务实例，利用集群的能力去对抗高并发，负载均衡是服务集群化的实施要素，

负载均衡分3种：

* DNS负载均衡
    * 客户端通过URL发起网络服务请求的时候，会去DNS服务器做域名解释，
    * DNS会按一定的策略（比如就近策略）把URL转换成IP地址，同一个URL会被解释成不同的IP地址，这便是DNS负载均衡，
    * DNS是一种粗粒度的负载均衡，它只用URL前半部分，因为DNS负载均衡一般采用就近原则，所以通常能降低时延，
    * 但DNS有cache，所以也会更新不及时的问题。
* 硬件负载均衡
    * 通过布置特殊的负载均衡设备到机房做负载均衡，比如F5，这种设备贵，性能高，可以支撑每秒百万并发，还能做一些安全防护，比如防火墙。
* 软件负载均衡
    * 根据工作在ISO 7层网络模型的层次，可分为四层负载均衡（比如章文嵩博士的LVS）和七层负载均衡（NGINX），
    * 软件负载均衡配置灵活，扩展性强，阿某云的SLB作为服务对外售卖，Nginx可以对URL的后半部做解释承担API网关的职责。

所以，完整的负载均衡链路是 client <-> DNS负载均衡 -> F5 -> LVS/SLB -> NGINX

---

## 数据库层面：分库分表 + 读写分离

数据库的单机QPS一般不高，也就几千，存储有可能成为系统的瓶颈，显然满足不了高并发的要求。所以，我们需要做分库分表 + 读写分离。

就是把一个库分成多个库，部署在多个数据库服务上，主库承载写请求，从库承载读请求。从库可以挂载多个，因为很多场景写的请求远少于读的请求，这样就把对单个库的压力降下来了。

如果写的请求上升就继续分库分表，如果读的请求上升就挂更多的从库，但数据库天生不是很适合高并发，而且数据库对机器配置的要求一般很高，导致单位服务成本高，所以，这样加机器抗压力成本太高，还得另外想招。

### 读多写少：缓存（读高并发）

针对写少读多的场景，很适合引入缓存集群，缓存集群来承载大部分的读请求，因为缓存集群很容易做到高性能，就可以用更少的机器资源承载更高的并发。

缓存的命中率一般能做到很高，而且速度很快，处理能力也强（单机很容易做到几万并发），是理想的解决方案。

CDN本质上就是缓存，被用户大量访问的静态资源缓存在CDN中是目前的通用做法。

### 高写入：消息中间件（写入高并发）

相同的资源下，数据库系统太重太复杂，所以并发承载能力就在几千/s的量级，所以此时你需要引入别的一些技术。

比如说消息中间件技术，也就是MQ集群，它是非常好的做写请求异步化处理，实现削峰填谷的效果。

消息队列能做解耦，在只需要最终一致性的场景下，很适合用来配合做流控。

假如说，每秒是1万次写请求，其中比如5千次请求是必须请求过来立马写入数据库中的，但是另外5千次写请求是可以允许异步化延时个几十秒，甚至几分钟后才落入数据库内的。

那么此时完全可以引入消息中间件集群，把允许异步化的每秒5千次请求写入MQ，然后基于MQ做一个削峰填谷。比如就以平稳的1000/s的速度消费出来然后落入数据库中即可，此时就会大幅度降低数据库的写入压力。

业界有很多著名的消息中间件，比如ZeroMQ，rabbitMQ，kafka等。

消息队列本身也跟缓存系统一样，可以用很少的资源支撑很高的并发请求，用它来支撑部分允许异步化的高并发写入是很合适的，比使用数据库直接支撑那部分高并发请求要减少很多的机器使用量。

---

## 限流算法：流量控制

再强大的系统，也怕流量短事件内集中爆发，就像银行怕挤兑一样，所以，高并发另一个必不可少的模块就是流控。

**限流可以应对：**

- 热点业务带来的突发请求；
- 调用方 bug 导致的突发请求；
- 恶意攻击请求。

### 计数器算法（固定窗口）：

![img](http://haoimg.hifool.cn/img/8ded7a2b90e1482093f92fff555b3615-20210314212506615.png)

* 将时间划分为多个窗口；
* 在每个窗口内每有一次请求就将计数器加一；
* 如果计数器超过了限制数量，则本窗口内所有的请求都被丢弃（触发限流策略）
* 当时间到达下一个窗口时，计数器重置。

**存在很大的弊端，有严重的临界问题，有时会让通过请求量允许为限制的两倍。**

* 限制 1 秒内最多通过 5 个请求，
* 在第一个窗口的最后半秒内通过了 5 个请求，
* 第二个窗口的前半秒内又通过了 5 个请求。
* 这样看来就是在 1 秒内通过了 10 个请求。

![img](http://haoimg.hifool.cn/img/4d03e8e43a8edc3f32376d90e52b85f4.png)

---

### 滑动窗口算法：

* 将时间周期分为N个区间，分别记录每个区间内访问次数，
* 每经过一个区间的时间，则抛弃最老的一个区间，并纳入最新的一个区间；
* 如果当前窗口内区间的请求计数总和超过了限制数量，则本窗口内所有的请求都被丢弃。
* 当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。
* **此算法可以很好的解决固定窗口算法的临界问题。**
    * 这种算法避免了固定窗口计数器带来的双倍突发请求，但时间区间的精度越高，算法所需的空间容量就越大。

![img](http://haoimg.hifool.cn/img/ae4d3cd14efb8dc7046d691c90264715.png)

---

### 漏桶算法：

![img](http://haoimg.hifool.cn/img/75938d1010138ce66e38c6ed0392f103.png)

- 将每个请求视作"水滴"放入"漏桶"进行存储；
- “漏桶"以固定速率向外"漏"出请求来执行如果"漏桶"空了则停止"漏水”；
- 如果"漏桶"满了则多余的"水滴"会被直接丢弃。

**漏桶算法多使用队列实现**

* 服务的请求会存到队列中，服务的提供方则按照固定的速率从队列中取出请求并执行，过多的请求则放在队列中排队或直接拒绝。

**漏桶算法的缺陷也很明显**

* 当短时间内有大量的突发请求时，即便此时服务器没有任何负载，每个请求也都得在队列中等待一段时间才能被响应。

---

### 令牌桶算法：

![img](http://haoimg.hifool.cn/img/eca0e5eaa35dac938c673fecf2ec9a93.png)

- 令牌以固定速率r（r=时间周期/限流值）生成；
- 生成的令牌放入令牌桶中存放，如果令牌桶满了则多余的令牌会直接丢弃，当请求到达时，会尝试从令牌桶中取令牌，取到了令牌的请求可以执行；
- 如果桶空了，那么尝试取令牌的请求会被直接丢弃。

令牌桶算法既能够将所有的请求平均分布到时间区间内，又能接受服务器能够承受范围内的突发请求，因此是目前使用较为广泛的一种限流算法。

---

## 总结： 单机性能优化和水平拓展

1. 把单机的性能做到极致，
2. 单机的性能做个瓶颈之后，通过部署多台机器实现无限水平拓展，也就是通过加机器来继续提升性能

读高并发一般通过缓存的手段来解决

写的高并发：

1. 允许有一定延时性的话，可以先用队列缓冲下并发请求，然后再写入数据库。
2. 水平拓展加机器部署服务和加数据库来抗住并发写.